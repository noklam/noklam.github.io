{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "badges: true\n",
    "date: '2022-11-15'\n",
    "description: 'Kedro Meet the Duck'\n",
    "output-file: kedro-duckdb.html\n",
    "title: 'Testing Kedro with DuckDB'\n",
    "toc: true\n",
    "categories:\n",
    "- python\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring DuckDB and how can we use it with `kedro`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "Extend the notebook from:\n",
    "https://colab.research.google.com/drive/1eg_TJpPQr2tyYKWjISJlX8IEAi8Qln3U?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Practical SQL for Data Analysis**\n",
    "### What you can do *together with* Pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "import duckdb\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparation**\n",
    "\n",
    "Download the data and set up the Pandas data frames. We read the data into a Pandas DataFrame using DuckDB's built-in Parquet reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  HTTP/1.1 301 Moved Permanently\n",
      "  Server: GitHub.com\n",
      "  Date: Tue, 15 Nov 2022 22:34:17 GMT\n",
      "  Content-Type: text/html; charset=utf-8\n",
      "  Vary: X-PJAX, X-PJAX-Container, Turbo-Visit, Turbo-Frame, Accept-Encoding, Accept, X-Requested-With\n",
      "  Location: https://github.com/duckdb/duckdb-data/releases/download/v1.0/lineitemsf1.snappy.parquet\n",
      "  Cache-Control: no-cache\n",
      "  Strict-Transport-Security: max-age=31536000; includeSubdomains; preload\n",
      "  X-Frame-Options: deny\n",
      "  X-Content-Type-Options: nosniff\n",
      "  X-XSS-Protection: 0\n",
      "  Referrer-Policy: origin-when-cross-origin, strict-origin-when-cross-origin\n",
      "  Content-Security-Policy: default-src 'none'; base-uri 'self'; block-all-mixed-content; child-src github.com/assets-cdn/worker/ gist.github.com/assets-cdn/worker/; connect-src 'self' uploads.github.com objects-origin.githubusercontent.com www.githubstatus.com collector.github.com raw.githubusercontent.com api.github.com github-cloud.s3.amazonaws.com github-production-repository-file-5c1aeb.s3.amazonaws.com github-production-upload-manifest-file-7fdce7.s3.amazonaws.com github-production-user-asset-6210df.s3.amazonaws.com cdn.optimizely.com logx.optimizely.com/v1/events *.actions.githubusercontent.com wss://*.actions.githubusercontent.com online.visualstudio.com/api/v1/locations github-production-repository-image-32fea6.s3.amazonaws.com github-production-release-asset-2e65be.s3.amazonaws.com insights.github.com wss://alive.github.com; font-src github.githubassets.com; form-action 'self' github.com gist.github.com objects-origin.githubusercontent.com; frame-ancestors 'none'; frame-src viewscreen.githubusercontent.com notebooks.githubusercontent.com; img-src 'self' data: github.githubassets.com media.githubusercontent.com camo.githubusercontent.com identicons.github.com avatars.githubusercontent.com github-cloud.s3.amazonaws.com objects.githubusercontent.com objects-origin.githubusercontent.com secured-user-images.githubusercontent.com/ opengraph.githubassets.com github-production-user-asset-6210df.s3.amazonaws.com customer-stories-feed.github.com spotlights-feed.github.com *.githubusercontent.com; manifest-src 'self'; media-src github.com user-images.githubusercontent.com/ secured-user-images.githubusercontent.com/; script-src github.githubassets.com; style-src 'unsafe-inline' github.githubassets.com; worker-src github.com/assets-cdn/worker/ gist.github.com/assets-cdn/worker/\n",
      "  Content-Length: 0\n",
      "  X-GitHub-Request-Id: D47F:F2DE:2F3E29B:303AC52:637413E9\n",
      "  HTTP/1.1 302 Found\n",
      "  Server: GitHub.com\n",
      "  Date: Tue, 15 Nov 2022 22:34:17 GMT\n",
      "  Content-Type: text/html; charset=utf-8\n",
      "  Vary: X-PJAX, X-PJAX-Container, Turbo-Visit, Turbo-Frame, Accept-Encoding, Accept, X-Requested-With\n",
      "  Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/263853960/33e88e80-95cb-11ea-8bb7-2dfa0654592c?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20221115%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20221115T223417Z&X-Amz-Expires=300&X-Amz-Signature=07d1673053f9e8676510f46b62993e3b9b2428a17f00a613162f67690318e82f&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=263853960&response-content-disposition=attachment%3B%20filename%3Dlineitemsf1.snappy.parquet&response-content-type=application%2Foctet-stream\n",
      "  Cache-Control: no-cache\n",
      "  Strict-Transport-Security: max-age=31536000; includeSubdomains; preload\n",
      "  X-Frame-Options: deny\n",
      "  X-Content-Type-Options: nosniff\n",
      "  X-XSS-Protection: 0\n",
      "  Referrer-Policy: no-referrer-when-downgrade\n",
      "  Content-Security-Policy: default-src 'none'; base-uri 'self'; block-all-mixed-content; child-src github.com/assets-cdn/worker/ gist.github.com/assets-cdn/worker/; connect-src 'self' uploads.github.com objects-origin.githubusercontent.com www.githubstatus.com collector.github.com raw.githubusercontent.com api.github.com github-cloud.s3.amazonaws.com github-production-repository-file-5c1aeb.s3.amazonaws.com github-production-upload-manifest-file-7fdce7.s3.amazonaws.com github-production-user-asset-6210df.s3.amazonaws.com cdn.optimizely.com logx.optimizely.com/v1/events *.actions.githubusercontent.com wss://*.actions.githubusercontent.com online.visualstudio.com/api/v1/locations github-production-repository-image-32fea6.s3.amazonaws.com github-production-release-asset-2e65be.s3.amazonaws.com insights.github.com wss://alive.github.com; font-src github.githubassets.com; form-action 'self' github.com gist.github.com objects-origin.githubusercontent.com; frame-ancestors 'none'; frame-src viewscreen.githubusercontent.com notebooks.githubusercontent.com; img-src 'self' data: github.githubassets.com media.githubusercontent.com camo.githubusercontent.com identicons.github.com avatars.githubusercontent.com github-cloud.s3.amazonaws.com objects.githubusercontent.com objects-origin.githubusercontent.com secured-user-images.githubusercontent.com/ opengraph.githubassets.com github-production-user-asset-6210df.s3.amazonaws.com customer-stories-feed.github.com spotlights-feed.github.com *.githubusercontent.com; manifest-src 'self'; media-src github.com user-images.githubusercontent.com/ secured-user-images.githubusercontent.com/; script-src github.githubassets.com; style-src 'unsafe-inline' github.githubassets.com; worker-src github.com/assets-cdn/worker/ gist.github.com/assets-cdn/worker/\n",
      "  Content-Length: 0\n",
      "  X-GitHub-Request-Id: D47F:F2DE:2F3E323:303ACEF:637413E9\n",
      "  HTTP/1.1 200 OK\n",
      "  Connection: keep-alive\n",
      "  Content-Length: 206368635\n",
      "  Content-Type: application/octet-stream\n",
      "  Last-Modified: Tue, 07 Dec 2021 13:35:44 GMT\n",
      "  ETag: \"0x8D9B986787C89B4\"\n",
      "  Server: Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0\n",
      "  x-ms-request-id: b588900b-a01e-0060-6d42-f95efa000000\n",
      "  x-ms-version: 2020-04-08\n",
      "  x-ms-creation-time: Tue, 17 Aug 2021 11:28:44 GMT\n",
      "  x-ms-lease-status: unlocked\n",
      "  x-ms-lease-state: available\n",
      "  x-ms-blob-type: BlockBlob\n",
      "  Content-Disposition: attachment; filename=lineitemsf1.snappy.parquet\n",
      "  x-ms-server-encrypted: true\n",
      "  Fastly-Restarts: 1\n",
      "  Accept-Ranges: bytes\n",
      "  Age: 0\n",
      "  Date: Tue, 15 Nov 2022 22:34:18 GMT\n",
      "  Via: 1.1 varnish\n",
      "  X-Served-By: cache-lhr7337-LHR\n",
      "  X-Cache: MISS\n",
      "  X-Cache-Hits: 0\n",
      "  X-Timer: S1668551658.108887,VS0,VE259\n"
     ]
    }
   ],
   "source": [
    "!wget -q https://github.com/cwida/duckdb-data/releases/download/v1.0/lineitemsf1.snappy.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/cwida/duckdb-data/releases/download/v1.0/orders.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.62 s, sys: 5.43 s, total: 13 s\n",
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lineitem = duckdb.query(\"SELECT * FROM 'lineitemsf1.snappy.parquet'\").to_df()\n",
    "orders = duckdb.query(\"SELECT * FROM 'orders.parquet'\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.29 s, sys: 1.5 s, total: 7.78 s\n",
      "Wall time: 5.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = pd.read_parquet(\"lineitemsf1.snappy.parquet\")\n",
    "_ = pd.read_parquet(\"orders.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = duckdb.connect()\n",
    "con.execute('PRAGMA threads=2')\n",
    "\n",
    "def timeit(fun, name):\n",
    "\timport time\n",
    "\tstart_time = time.monotonic()\n",
    "\tfun()\n",
    "\treturn [name, time.monotonic() - start_time]\n",
    "\n",
    "def plot_results(results, title):\n",
    "  df = pd.DataFrame.from_dict({\n",
    "      'name': [x[0] for x in results],\n",
    "      'time': [x[1] for x in results]\n",
    "  })\n",
    "  print(title)\n",
    "  print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ungrouped Aggregates**\n",
    "\n",
    "This performs a simple set of ungrouped aggregates (sum, min, max, avg) over a column without any filters or other complex operations.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sum(l_extendedprice)  min(l_extendedprice)  max(l_extendedprice)  \\\n",
      "0          2.295773e+11                 901.0              104949.5   \n",
      "\n",
      "   avg(l_extendedprice)  \n",
      "0          38255.138485  \n",
      "   sum(l_extendedprice)  min(l_extendedprice)  max(l_extendedprice)  \\\n",
      "0          2.295773e+11                 901.0              104949.5   \n",
      "\n",
      "   avg(l_extendedprice)  \n",
      "0          38255.138485  \n",
      "                                    Sum    Min       Max           Avg\n",
      "l_returnflag l_linestatus                                             \n",
      "A            F             5.658655e+10  904.0  104949.5  38273.129735\n",
      "N            F             1.487505e+09  920.0  104049.5  38284.467761\n",
      "             O             1.149352e+11  901.0  104749.5  38248.015609\n",
      "R            F             5.656804e+10  904.0  104899.5  38250.854626\n",
      "Ungrouped Aggregate\n",
      "          name      time\n",
      "0  DuckDB (1T)  0.052544\n",
      "1  DuckDB (2T)  0.066239\n",
      "2       Pandas  0.801278\n"
     ]
    }
   ],
   "source": [
    "ungrouped_aggregate = '''\n",
    "    SELECT SUM(l_extendedprice), MIN(l_extendedprice), MAX(l_extendedprice), AVG(l_extendedprice) FROM lineitem\n",
    "'''\n",
    "\n",
    "def duckdb_ungrouped_aggregate(d_con):\n",
    "\tprint(d_con.query(ungrouped_aggregate).to_df())\n",
    "\n",
    "def duckdb_ungrouped_aggregate_1t():\n",
    "\tduckdb_ungrouped_aggregate(duckdb)\n",
    "\n",
    "def duckdb_ungrouped_aggregate_2t():\n",
    "\tduckdb_ungrouped_aggregate(con)\n",
    "\n",
    "def pandas_ungrouped_aggregate():\n",
    "  result = lineitem.groupby(\n",
    "    ['l_returnflag', 'l_linestatus']\n",
    "  ).agg(\n",
    "    Sum=('l_extendedprice', 'sum'),\n",
    "    Min=('l_extendedprice', 'min'),\n",
    "    Max=('l_extendedprice', 'max'),\n",
    "    Avg=('l_extendedprice', 'mean')\n",
    "  )\n",
    "  print(result)\n",
    "\t# print(lineitem.agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean')))\n",
    "\n",
    "ua_results = []\n",
    "ua_results.append(timeit(duckdb_ungrouped_aggregate_1t, 'DuckDB (1T)'))\n",
    "ua_results.append(timeit(duckdb_ungrouped_aggregate_2t, 'DuckDB (2T)'))\n",
    "ua_results.append(timeit(pandas_ungrouped_aggregate, 'Pandas'))\n",
    "plot_results(ua_results, 'Ungrouped Aggregate')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouped Aggregates**\n",
    "\n",
    "This performs the same set of aggregates, but this time grouped by two other columns (*l_returnflag* and *l_linestatus*).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  l_returnflag l_linestatus  sum(l_extendedprice)  min(l_extendedprice)  \\\n",
      "0            N            O          1.149352e+11                 901.0   \n",
      "1            R            F          5.656804e+10                 904.0   \n",
      "2            A            F          5.658655e+10                 904.0   \n",
      "3            N            F          1.487505e+09                 920.0   \n",
      "\n",
      "   max(l_extendedprice)  avg(l_extendedprice)  \n",
      "0              104749.5          38248.015609  \n",
      "1              104899.5          38250.854626  \n",
      "2              104949.5          38273.129735  \n",
      "3              104049.5          38284.467761  \n",
      "  l_returnflag l_linestatus  sum(l_extendedprice)  min(l_extendedprice)  \\\n",
      "0            N            O          1.149352e+11                 901.0   \n",
      "1            R            F          5.656804e+10                 904.0   \n",
      "2            A            F          5.658655e+10                 904.0   \n",
      "3            N            F          1.487505e+09                 920.0   \n",
      "\n",
      "   max(l_extendedprice)  avg(l_extendedprice)  \n",
      "0              104749.5          38248.015609  \n",
      "1              104899.5          38250.854626  \n",
      "2              104949.5          38273.129735  \n",
      "3              104049.5          38284.467761  \n",
      "                                    Sum    Min       Max           Avg\n",
      "l_returnflag l_linestatus                                             \n",
      "A            F             5.658655e+10  904.0  104949.5  38273.129735\n",
      "N            F             1.487505e+09  920.0  104049.5  38284.467761\n",
      "             O             1.149352e+11  901.0  104749.5  38248.015609\n",
      "R            F             5.656804e+10  904.0  104899.5  38250.854626\n",
      "Grouped Aggregate\n",
      "          name      time\n",
      "0  DuckDB (1T)  0.115463\n",
      "1  DuckDB (2T)  0.222520\n",
      "2       Pandas  0.708696\n"
     ]
    }
   ],
   "source": [
    "grouped_aggregate = '''\n",
    "SELECT l_returnflag,\n",
    "       l_linestatus,\n",
    "       SUM(l_extendedprice),\n",
    "       MIN(l_extendedprice),\n",
    "       MAX(l_extendedprice),\n",
    "       AVG(l_extendedprice)\n",
    "FROM lineitem\n",
    "GROUP BY l_returnflag,\n",
    "         l_linestatus\n",
    "'''\n",
    "\n",
    "def duckdb_grouped_aggregate(d_con):\n",
    "\tprint(d_con.query(grouped_aggregate).to_df())\n",
    "\n",
    "def duckdb_grouped_aggregate_1t():\n",
    "\tduckdb_grouped_aggregate(duckdb)\n",
    "\n",
    "def duckdb_grouped_aggregate_2t():\n",
    "\tduckdb_grouped_aggregate(con)\n",
    "\n",
    "def pandas_grouped_aggregate():\n",
    "\tprint(lineitem.groupby(['l_returnflag', 'l_linestatus']).agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean')))\n",
    "\n",
    "results = []\n",
    "results.append(timeit(duckdb_grouped_aggregate_1t, 'DuckDB (1T)'))\n",
    "results.append(timeit(duckdb_grouped_aggregate_2t, 'DuckDB (2T)'))\n",
    "results.append(timeit(pandas_grouped_aggregate, 'Pandas'))\n",
    "plot_results(results, 'Grouped Aggregate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouped Aggregate with a Filter**\n",
    "\n",
    "This benchmark performs a grouped aggregate with a filter over the shipdate column.\n",
    "\n",
    "As Pandas does not perform any projection pushdown, we include a version where we manually perform the projection pushdown by filtering only the columns we actually need before running the filter and aggregate.\n",
    "\n",
    "This optimization is performed automatically in DuckDB by the query optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  l_returnflag l_linestatus  sum(l_extendedprice)  min(l_extendedprice)  \\\n",
      "0            N            O          1.117017e+11                 901.0   \n",
      "1            A            F          5.658655e+10                 904.0   \n",
      "2            R            F          5.656804e+10                 904.0   \n",
      "3            N            F          1.487505e+09                 920.0   \n",
      "\n",
      "   max(l_extendedprice)  avg(l_extendedprice)  \n",
      "0              104749.5          38249.117989  \n",
      "1              104949.5          38273.129735  \n",
      "2              104899.5          38250.854626  \n",
      "3              104049.5          38284.467761  \n",
      "  l_returnflag l_linestatus  sum(l_extendedprice)  min(l_extendedprice)  \\\n",
      "0            N            O          1.117017e+11                 901.0   \n",
      "1            A            F          5.658655e+10                 904.0   \n",
      "2            R            F          5.656804e+10                 904.0   \n",
      "3            N            F          1.487505e+09                 920.0   \n",
      "\n",
      "   max(l_extendedprice)  avg(l_extendedprice)  \n",
      "0              104749.5          38249.117989  \n",
      "1              104949.5          38273.129735  \n",
      "2              104899.5          38250.854626  \n",
      "3              104049.5          38284.467761  \n",
      "                                    Sum    Min       Max           Avg\n",
      "l_returnflag l_linestatus                                             \n",
      "A            F             5.658655e+10  904.0  104949.5  38273.129735\n",
      "N            F             1.487505e+09  920.0  104049.5  38284.467761\n",
      "             O             1.116318e+11  901.0  104749.5  38249.322811\n",
      "R            F             5.656804e+10  904.0  104899.5  38250.854626\n",
      "                                    Sum    Min       Max           Avg\n",
      "l_returnflag l_linestatus                                             \n",
      "A            F             5.658655e+10  904.0  104949.5  38273.129735\n",
      "N            F             1.487505e+09  920.0  104049.5  38284.467761\n",
      "             O             1.116318e+11  901.0  104749.5  38249.322811\n",
      "R            F             5.656804e+10  904.0  104899.5  38250.854626\n",
      "Grouped Aggregate + Filter\n",
      "                       name      time\n",
      "0               DuckDB (1T)  0.281653\n",
      "1               DuckDB (2T)  0.356302\n",
      "2                    Pandas  2.889015\n",
      "3  Pandas (manual pushdown)  1.625353\n"
     ]
    }
   ],
   "source": [
    "def duckdb_grouped_aggregate_filter(d_con):\n",
    "\tprint(d_con.query('''\n",
    "SELECT l_returnflag,\n",
    "       l_linestatus,\n",
    "       SUM(l_extendedprice),\n",
    "       MIN(l_extendedprice),\n",
    "       MAX(l_extendedprice),\n",
    "       AVG(l_extendedprice)\n",
    "FROM lineitem\n",
    "WHERE\n",
    "    l_shipdate <= DATE '1998-09-02'\n",
    "GROUP BY l_returnflag,\n",
    "         l_linestatus\n",
    "''').to_df())\n",
    "\n",
    "def duckdb_grouped_aggregate_filter_1t():\n",
    "\tduckdb_grouped_aggregate_filter(duckdb)\n",
    "\n",
    "def duckdb_grouped_aggregate_filter_2t():\n",
    "\tduckdb_grouped_aggregate_filter(con)\n",
    "\n",
    "def pandas_grouped_aggregate_filter():\n",
    "  filtered_df = lineitem[lineitem['l_shipdate'] < \"1998-09-02\"]\n",
    "  print(filtered_df.groupby(['l_returnflag', 'l_linestatus']).agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean')))\n",
    "\n",
    "def pandas_grouped_aggregate_filter_projection_pushdown():\n",
    "  pushed_down_df = lineitem[['l_shipdate', 'l_returnflag', 'l_linestatus', 'l_extendedprice']]\n",
    "  filtered_df = pushed_down_df[pushed_down_df['l_shipdate'] < \"1998-09-02\"]\n",
    "  print(filtered_df.groupby(['l_returnflag', 'l_linestatus']).agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean')))\n",
    "\n",
    "results = []\n",
    "results.append(timeit(duckdb_grouped_aggregate_filter_1t, 'DuckDB (1T)'))\n",
    "results.append(timeit(duckdb_grouped_aggregate_filter_2t, 'DuckDB (2T)'))\n",
    "results.append(timeit(pandas_grouped_aggregate_filter, 'Pandas'))\n",
    "results.append(timeit(pandas_grouped_aggregate_filter_projection_pushdown, 'Pandas (manual pushdown)'))\n",
    "plot_results(results, 'Grouped Aggregate + Filter')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Grouped Aggregate with Join and Filter**\n",
    "\n",
    "In this benchmark we expand on the previous benchmark by including a join and a filter on the joined-on table.\n",
    "\n",
    "Note that the naive version in Pandas is extremely slow, as it performs a full join of the entire table including all the columns that are not used and all the rows that will be filtered out. For that reason we have included a separate benchmark in which we have manually optimized the Pandas code by pushing down the projections and the filters.\n",
    "\n",
    "These optimizations are performed automatically in DuckDB by the query optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# projection & filter on lineitem table\n",
    "lineitem_projected = lineitem[\n",
    "  ['l_shipdate',\n",
    "   'l_orderkey',\n",
    "   'l_linestatus',\n",
    "   'l_returnflag',\n",
    "   'l_extendedprice']\n",
    "]\n",
    "lineitem_filtered = lineitem_projected[\n",
    "  lineitem_projected['l_shipdate'] < \"1998-09-02\"]\n",
    "# projection and filter on order table\n",
    "orders_projected = orders[\n",
    "  ['o_orderkey',\n",
    "   'o_orderstatus']\n",
    "]\n",
    "orders_filtered = orders_projected[\n",
    "  orders_projected['o_orderstatus'] == 'O']\n",
    "# perform the join\n",
    "merged = lineitem_filtered.merge(\n",
    "  orders_filtered,\n",
    "  left_on='l_orderkey',\n",
    "  right_on='o_orderkey')\n",
    "# perform the aggregate\n",
    "result = merged.groupby(\n",
    "  ['l_returnflag', 'l_linestatus']\n",
    ").agg(\n",
    "  Sum=('l_extendedprice', 'sum'),\n",
    "  Min=('l_extendedprice', 'min'),\n",
    "  Max=('l_extendedprice', 'max'),\n",
    "  Avg=('l_extendedprice', 'mean')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Sum</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>Avg</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l_returnflag</th>\n",
       "      <th>l_linestatus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>N</th>\n",
       "      <th>O</th>\n",
       "      <td>1.080448e+11</td>\n",
       "      <td>901.0</td>\n",
       "      <td>104749.5</td>\n",
       "      <td>38250.662806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Sum    Min       Max           Avg\n",
       "l_returnflag l_linestatus                                             \n",
       "N            O             1.080448e+11  901.0  104749.5  38250.662806"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  l_returnflag l_linestatus  sum(l_extendedprice)  min(l_extendedprice)  \\\n",
      "0            N            O          1.081147e+11                 901.0   \n",
      "\n",
      "   max(l_extendedprice)  avg(l_extendedprice)  \n",
      "0              104749.5          38250.450307  \n",
      "  l_returnflag l_linestatus  sum(l_extendedprice)  min(l_extendedprice)  \\\n",
      "0            N            O          1.081147e+11                 901.0   \n",
      "\n",
      "   max(l_extendedprice)  avg(l_extendedprice)  \n",
      "0              104749.5          38250.450307  \n",
      "                                    Sum    Min       Max           Avg\n",
      "l_returnflag l_linestatus                                             \n",
      "N            O             1.080448e+11  901.0  104749.5  38250.662806\n",
      "                                    Sum    Min       Max           Avg\n",
      "l_returnflag l_linestatus                                             \n",
      "N            O             1.080448e+11  901.0  104749.5  38250.662806\n",
      "Grouped Aggregate Join\n",
      "                       name       time\n",
      "0               DuckDB (1T)   0.218088\n",
      "1               DuckDB (2T)   0.376592\n",
      "2                    Pandas  11.403579\n",
      "3  Pandas (manual pushdown)   2.765103\n"
     ]
    }
   ],
   "source": [
    "def duckdb_grouped_aggregate_filter_join(d_con):\n",
    "\tprint(d_con.query('''\n",
    "SELECT l_returnflag,\n",
    "       l_linestatus,\n",
    "       sum(l_extendedprice),\n",
    "       min(l_extendedprice),\n",
    "       max(l_extendedprice),\n",
    "       avg(l_extendedprice)\n",
    "FROM lineitem lineitem\n",
    "JOIN orders orders ON (l_orderkey=o_orderkey)\n",
    "WHERE l_shipdate <= DATE '1998-09-02'\n",
    "  AND o_orderstatus='O'\n",
    "GROUP BY l_returnflag,\n",
    "         l_linestatus\n",
    "''').to_df())\n",
    "\n",
    "def duckdb_grouped_aggregate_filter_join_1t():\n",
    "\tduckdb_grouped_aggregate_filter_join(duckdb)\n",
    "\n",
    "def duckdb_grouped_aggregate_filter_join_2t():\n",
    "\tduckdb_grouped_aggregate_filter_join(con)\n",
    "\n",
    "def pandas_grouped_aggregate_filter_join():\n",
    "\tmerged = lineitem.merge(orders, left_on='l_orderkey', right_on='o_orderkey')\n",
    "\tfiltered_a = merged[merged['l_shipdate'] < \"1998-09-02\"]\n",
    "\tfiltered_b = filtered_a[filtered_a['o_orderstatus'] == 'O']\n",
    "\tresult = filtered_b.groupby(['l_returnflag', 'l_linestatus']).agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean'))\n",
    "\tprint(result)\n",
    "\n",
    "def pandas_grouped_aggregate_filter_join_manual_pushdown():\n",
    "\tlineitem_projected = lineitem[['l_shipdate', 'l_orderkey', 'l_linestatus', 'l_returnflag', 'l_extendedprice']]\n",
    "\tlineitem_filtered = lineitem_projected[lineitem_projected['l_shipdate'] < \"1998-09-02\"]\n",
    "\torders_projected = orders[['o_orderkey', 'o_orderstatus']]\n",
    "\torders_filtered = orders_projected[orders_projected['o_orderstatus'] == 'O']\n",
    "\tmerged = lineitem_filtered.merge(orders_filtered, left_on='l_orderkey', right_on='o_orderkey')\n",
    "\tresult = merged.groupby(['l_returnflag', 'l_linestatus']).agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean'))\n",
    "\tprint(result)\n",
    "\n",
    "results = []\n",
    "results.append(timeit(duckdb_grouped_aggregate_filter_join_1t, 'DuckDB (1T)'))\n",
    "results.append(timeit(duckdb_grouped_aggregate_filter_join_2t, 'DuckDB (2T)'))\n",
    "results.append(timeit(pandas_grouped_aggregate_filter_join, 'Pandas'))\n",
    "results.append(timeit(pandas_grouped_aggregate_filter_join_manual_pushdown, 'Pandas (manual pushdown)'))\n",
    "plot_results(results, 'Grouped Aggregate Join')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix A: There and back again: Transferring data from Pandas to a SQL engine and back\n",
    "\n",
    "As Appendix A relies on the presence of an external PostgreSQL database server, the code cannot be executed in colab. The source code can be found here: https://gist.github.com/hannesmuehleisen/a95a39a1eda63aeb0ca13fd82d1ba49c\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix B: PandasSQL\n",
    "\n",
    "Note: we cannot run this on the original dataset, as colab will run out of memory and crash. Instead for the benchmark we add a sample clause to reduce the data set size to 10% of the original data set size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet pandasql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandasql as psql\n",
    "pysqldf = lambda q: psql.sqldf(q, globals())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineitem_sample = duckdb.query(\"SELECT * FROM 'lineitemsf1.snappy.parquet' USING SAMPLE 10%\").to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sum(l_extendedprice)  min(l_extendedprice)  max(l_extendedprice)  \\\n",
      "0          2.318151e+10                 907.0              104899.5   \n",
      "\n",
      "   avg(l_extendedprice)  \n",
      "0          38240.198955  \n",
      "   sum(l_extendedprice)  min(l_extendedprice)  max(l_extendedprice)  \\\n",
      "0          2.318151e+10                 907.0              104899.5   \n",
      "\n",
      "   avg(l_extendedprice)  \n",
      "0          38240.198955  \n",
      "     l_extendedprice\n",
      "Sum     2.318151e+10\n",
      "Min     9.070000e+02\n",
      "Max     1.048995e+05\n",
      "Avg     3.824020e+04\n",
      "   SUM(l_extendedprice)  MIN(l_extendedprice)  MAX(l_extendedprice)  \\\n",
      "0          2.318151e+10                 907.0              104899.5   \n",
      "\n",
      "   AVG(l_extendedprice)  \n",
      "0          38240.198955  \n",
      "Ungrouped Aggregate\n",
      "          name      time\n",
      "0  DuckDB (1T)  0.039731\n",
      "1  DuckDB (2T)  0.033024\n",
      "2       Pandas  0.012675\n",
      "3     PandaSQL  9.181672\n"
     ]
    }
   ],
   "source": [
    "ungrouped_aggregate = '''\n",
    "    SELECT SUM(l_extendedprice), MIN(l_extendedprice), MAX(l_extendedprice), AVG(l_extendedprice) FROM lineitem_sample\n",
    "'''\n",
    "\n",
    "def duckdb_ungrouped_aggregate(d_con):\n",
    "\tprint(d_con.query(ungrouped_aggregate).to_df())\n",
    "\n",
    "def duckdb_ungrouped_aggregate_1t():\n",
    "\tduckdb_ungrouped_aggregate(duckdb)\n",
    "\n",
    "def duckdb_ungrouped_aggregate_2t():\n",
    "\tduckdb_ungrouped_aggregate(con)\n",
    "\n",
    "def pandas_ungrouped_aggregate():\n",
    "\tprint(lineitem_sample.agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean')))\n",
    "\n",
    "def ungrouped_aggregate_pandasql():\n",
    "  print(pysqldf(ungrouped_aggregate))\n",
    "\n",
    "ua_results = []\n",
    "ua_results.append(timeit(duckdb_ungrouped_aggregate_1t, 'DuckDB (1T)'))\n",
    "ua_results.append(timeit(duckdb_ungrouped_aggregate_2t, 'DuckDB (2T)'))\n",
    "ua_results.append(timeit(pandas_ungrouped_aggregate, 'Pandas'))\n",
    "ua_results.append(timeit(ungrouped_aggregate_pandasql, 'PandaSQL'))\n",
    "plot_results(ua_results, 'Ungrouped Aggregate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix C: Directly querying Parquet files\n",
    "\n",
    "In the benchmarks above, we fully read the parquet files into Pandas. However, DuckDB also has the capability of directly running queries on top of Parquet files. In this appendix, we show the performance of this compared to loading the file into Python first. \n",
    "\n",
    "You can even use the wildcard syntax to run queries on multiple Parquet files in the same folder and create a unified single-table view over them (as long as they have the same schema).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/Nok_Lam_Chan/miniconda3/envs/duckdb/lib/python3.9/site-packages (10.0.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/Nok_Lam_Chan/miniconda3/envs/duckdb/lib/python3.9/site-packages (from pyarrow) (1.23.4)\r\n"
     ]
    }
   ],
   "source": [
    "# need to install pyarrow for pandas parquet reading\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<duckdb.DuckDBPyConnection>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set up the view\n",
    "parquet_con = duckdb.connect()\n",
    "parquet_con.execute(\"CREATE VIEW lineitem_parquet AS SELECT * FROM 'lineitemsf1.snappy.parquet'\")\n",
    "parquet_con.execute(\"CREATE VIEW orders_parquet AS SELECT * FROM 'orders.parquet'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ungrouped Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sum(l_extendedprice)  min(l_extendedprice)  max(l_extendedprice)  \\\n",
      "0          2.295773e+11                 901.0              104949.5   \n",
      "\n",
      "   avg(l_extendedprice)  \n",
      "0          38255.138485  \n",
      "   sum(l_extendedprice)  min(l_extendedprice)  max(l_extendedprice)  \\\n",
      "0          2.295773e+11                 901.0              104949.5   \n",
      "\n",
      "   avg(l_extendedprice)  \n",
      "0          38255.138485  \n",
      "     l_extendedprice\n",
      "Sum     2.295773e+11\n",
      "Min     9.010000e+02\n",
      "Max     1.049495e+05\n",
      "Avg     3.825514e+04\n",
      "     l_extendedprice\n",
      "Sum     2.295773e+11\n",
      "Min     9.010000e+02\n",
      "Max     1.049495e+05\n",
      "Avg     3.825514e+04\n",
      "     l_extendedprice\n",
      "Sum     2.295773e+11\n",
      "Min     9.010000e+02\n",
      "Max     1.049495e+05\n",
      "Avg     3.825514e+04\n",
      "Ungrouped Aggregate (Parquet)\n",
      "                               name      time\n",
      "0                 DuckDB (1 Thread)  0.173902\n",
      "1                DuckDB (2 Threads)  0.086305\n",
      "2                            Pandas  0.050655\n",
      "3             Pandas + Parquet Load  6.311870\n",
      "4  Pandas + Parquet Load (Pushdown)  0.151299\n"
     ]
    }
   ],
   "source": [
    "ungrouped_aggregate = '''\n",
    "    SELECT SUM(l_extendedprice), MIN(l_extendedprice), MAX(l_extendedprice), AVG(l_extendedprice) FROM lineitem_parquet\n",
    "'''\n",
    "\n",
    "def duckdb_parquet_query(d_con):\n",
    "\tprint(d_con.query(ungrouped_aggregate).to_df())\n",
    "\n",
    "def duckdb_ungrouped_parquet_1t():\n",
    "  parquet_con.execute('PRAGMA threads=1')\n",
    "  duckdb_ungrouped_aggregate(parquet_con)\n",
    " \n",
    "def duckdb_ungrouped_parquet_2t():\n",
    "  parquet_con.execute('PRAGMA threads=2')\n",
    "  duckdb_ungrouped_aggregate(parquet_con)\n",
    "\n",
    "def pandas_ungrouped_aggregate():\n",
    "\tprint(lineitem.agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean')))\n",
    "\n",
    "def pandas_ungrouped_aggregate_parquet_load():\n",
    "  lineitem_pandas_parquet = pd.read_parquet('lineitemsf1.snappy.parquet')\n",
    "  print(lineitem_pandas_parquet.agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean')))\n",
    "\n",
    "def pandas_ungrouped_aggregate_parquet_load_pushdown():\n",
    "  lineitem_pandas_parquet = pd.read_parquet('lineitemsf1.snappy.parquet', columns=['l_extendedprice'])\n",
    "  print(lineitem_pandas_parquet.agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean')))\n",
    "\n",
    "ua_results = []\n",
    "ua_results.append(timeit(duckdb_ungrouped_parquet_1t, 'DuckDB (1 Thread)'))\n",
    "ua_results.append(timeit(duckdb_ungrouped_parquet_2t, 'DuckDB (2 Threads)'))\n",
    "ua_results.append(timeit(pandas_ungrouped_aggregate, 'Pandas'))\n",
    "ua_results.append(timeit(pandas_ungrouped_aggregate_parquet_load, 'Pandas + Parquet Load'))\n",
    "ua_results.append(timeit(pandas_ungrouped_aggregate_parquet_load_pushdown, 'Pandas + Parquet Load (Pushdown)'))\n",
    "plot_results(ua_results, 'Ungrouped Aggregate (Parquet)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouped Aggregate with Join and Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  l_returnflag l_linestatus  sum(l_extendedprice)  min(l_extendedprice)  \\\n",
      "0            N            O          1.081147e+11                 901.0   \n",
      "\n",
      "   max(l_extendedprice)  avg(l_extendedprice)  \n",
      "0              104749.5          38250.450307  \n",
      "  l_returnflag l_linestatus  sum(l_extendedprice)  min(l_extendedprice)  \\\n",
      "0            N            O          1.081147e+11                 901.0   \n",
      "\n",
      "   max(l_extendedprice)  avg(l_extendedprice)  \n",
      "0              104749.5          38250.450307  \n",
      "                                    Sum    Min       Max           Avg\n",
      "l_returnflag l_linestatus                                             \n",
      "N            O             1.080448e+11  901.0  104749.5  38250.662806\n",
      "                                    Sum    Min       Max           Avg\n",
      "l_returnflag l_linestatus                                             \n",
      "N            O             1.080448e+11  901.0  104749.5  38250.662806\n",
      "Grouped Aggregate Join (Parquet)\n",
      "                       name       time\n",
      "0               DuckDB (1T)   0.828549\n",
      "1               DuckDB (2T)   0.508537\n",
      "2                    Pandas  13.954761\n",
      "3  Pandas (manual pushdown)   2.337109\n"
     ]
    }
   ],
   "source": [
    "def duckdb_grouped_aggregate_filter_join_pq(d_con):\n",
    "\tprint(d_con.query('''\n",
    "SELECT l_returnflag,\n",
    "       l_linestatus,\n",
    "       sum(l_extendedprice),\n",
    "       min(l_extendedprice),\n",
    "       max(l_extendedprice),\n",
    "       avg(l_extendedprice)\n",
    "FROM lineitem_parquet lineitem\n",
    "JOIN orders_parquet orders ON (l_orderkey=o_orderkey)\n",
    "WHERE l_shipdate <= DATE '1998-09-02'\n",
    "  AND o_orderstatus='O'\n",
    "GROUP BY l_returnflag,\n",
    "         l_linestatus\n",
    "''').to_df())\n",
    "\n",
    "def duckdb_grouped_aggregate_filter_join_pq_1t():\n",
    "  parquet_con.execute('PRAGMA threads=1')\n",
    "  duckdb_grouped_aggregate_filter_join_pq(parquet_con)\n",
    "\n",
    "def duckdb_grouped_aggregate_filter_join_pq_2t():\n",
    "  parquet_con.execute('PRAGMA threads=2')\n",
    "  duckdb_grouped_aggregate_filter_join_pq(parquet_con)\n",
    "\n",
    "def pandas_grouped_aggregate_filter_join_pq():\n",
    "  lineitem_pandas_parquet = pd.read_parquet('lineitemsf1.snappy.parquet')\n",
    "  orders_pandas_parquet = pd.read_parquet('orders.parquet')\n",
    "  merged = lineitem_pandas_parquet.merge(orders, left_on='l_orderkey', right_on='o_orderkey')\n",
    "  filtered_a = merged[merged['l_shipdate'] < \"1998-09-02\"]\n",
    "  filtered_b = filtered_a[filtered_a['o_orderstatus'] == 'O']\n",
    "  result = filtered_b.groupby(['l_returnflag', 'l_linestatus']).agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean'))\n",
    "  print(result)\n",
    "\n",
    "def pandas_grouped_aggregate_filter_join_manual_pushdown_pq():\n",
    "  lineitem_projected = pd.read_parquet('lineitemsf1.snappy.parquet', columns=['l_shipdate', 'l_orderkey', 'l_linestatus', 'l_returnflag', 'l_extendedprice'])\n",
    "  orders_projected = pd.read_parquet('orders.parquet', columns=['o_orderkey', 'o_orderstatus'])\n",
    "  lineitem_filtered = lineitem_projected[lineitem_projected['l_shipdate'] < \"1998-09-02\"]\n",
    "  orders_filtered = orders_projected[orders_projected['o_orderstatus'] == 'O']\n",
    "  merged = lineitem_filtered.merge(orders_filtered, left_on='l_orderkey', right_on='o_orderkey')\n",
    "  result = merged.groupby(['l_returnflag', 'l_linestatus']).agg(Sum=('l_extendedprice', 'sum'), Min=('l_extendedprice', 'min'), Max=('l_extendedprice', 'max'), Avg=('l_extendedprice', 'mean'))\n",
    "  print(result)\n",
    "\n",
    "results = []\n",
    "results.append(timeit(duckdb_grouped_aggregate_filter_join_pq_1t, 'DuckDB (1T)'))\n",
    "results.append(timeit(duckdb_grouped_aggregate_filter_join_pq_2t, 'DuckDB (2T)'))\n",
    "results.append(timeit(pandas_grouped_aggregate_filter_join_pq, 'Pandas'))\n",
    "results.append(timeit(pandas_grouped_aggregate_filter_join_manual_pushdown_pq, 'Pandas (manual pushdown)'))\n",
    "plot_results(results, 'Grouped Aggregate Join (Parquet)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part II - Transform Pandas to DuckDB Query\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part III - Create the DuckDB DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part IV - Create the DuckDB Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.14 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "397704579725e15f5c7cb49fe5f0341eb7531c82d19f2c29d197e8b64ab5776b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
